import streamlit as st
import openai
import json
import pandas as pd
import numpy as np
import chromadb
from chromadb.config import Settings
from FlagEmbedding import BGEM3FlagModel
import torch
from transformers import AutoModel

############################
# 0) GPT API Key
############################
openai.api_key = "ê°œì¸_API_key"
client = openai.OpenAI(api_key=openai.api_key)

############################
# 0-1) [ìˆ˜ì •] jina ëª¨ë¸ ë˜í¼
############################
class JinaEmbeddingModel:
    """
    jinaai/jina-embeddings-v3 ëª¨ë¸ ë˜í¼
    """
    def __init__(self, model_name="jinaai/jina-embeddings-v3", device=None, task="text-matching", use_fp16=False):
        if device is None:
            device = "cuda" if torch.cuda.is_available() else "cpu"
        self.device = device
        self.task = task
        print(f"[JinaEmbeddingModel] loading {model_name} (task={self.task}, fp16={use_fp16}, device={self.device}) ...")
        self.model = AutoModel.from_pretrained(
            model_name,
            trust_remote_code=True
        ).to(self.device)

        self.model.eval()


        print("[JinaEmbeddingModel] loaded.")

    def encode(self, texts, max_length=8192, batch_size=32):
        """
        texts: List[str]
        returns dict: {"dense_vecs": np.ndarray(shape=(N, D))}
        """
        all_embeddings = []
        for start_idx in range(0, len(texts), batch_size):
            batch_texts = texts[start_idx:start_idx+batch_size]
            with torch.no_grad():
                embs = self.model.encode(
                    batch_texts,
                    task=self.task,
                    max_length=max_length
                )
            embs = embs if isinstance(embs, np.ndarray) else embs.detach().cpu().numpy()
            all_embeddings.extend(embs)
        return {"dense_vecs": np.array(all_embeddings)}

    def stop_self_pool(self):
        pass  # í•„ìš” ì‹œ ë©€í‹°í”„ë¡œì„¸ì‹± í’€ ì¢…ë£Œ ë¡œì§ ë“±
        
# ë“¤ì—¬ì“°ê¸° ì²˜ë¦¬ë¥¼ ìœ„í•œ ê¸°í˜¸ ëª©ë¡
INDENTATION_MARKERS = [
    "1)", "2)", "3)", "4)", "5)", "6)", "7)", "8)", "9)", "10)", "-", "[",
    "1. ", "2. ", "3. ", "4. ", "5. ", "6. ", "7. ", "8. ", "9.", "10. ",
    "â– ", "â—", "ã†", "Â·", "â€¢", "ã…‡", "â€œ", "â€˜", "[1]", "[2]", "[3]", "[4]", "[5]", "[6]", "[7]", "[8]", "[9]", "[10]",
    "(1)", "(2)", "(3)", "(4)", "(5)", "(6)", "(7)", "(8)", "(9)", "(10)", "â—‹", "â–ª", "â–¶","â€¢","ã€"
]

############################
# 1) ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
############################
if "selected_tab" not in st.session_state:
    st.session_state["selected_tab"] = "job_recommendation"

if "selected_sido" not in st.session_state:
    st.session_state["selected_sido"] = []

############################
# 2) í•œêµ­ ì‹œë„/ì‹œêµ°êµ¬ ë°ì´í„°
############################
location_dict = {
    "ì„œìš¸": ["ì¢…ë¡œêµ¬", "ì¤‘êµ¬", "ìš©ì‚°êµ¬", "ì„±ë™êµ¬", "ê´‘ì§„êµ¬", "ë™ëŒ€ë¬¸êµ¬", "ì¤‘ë‘êµ¬", "ì„±ë¶êµ¬",
             "ê°•ë¶êµ¬", "ë„ë´‰êµ¬", "ë…¸ì›êµ¬", "ì€í‰êµ¬", "ì„œëŒ€ë¬¸êµ¬", "ë§ˆí¬êµ¬", "ì–‘ì²œêµ¬",
             "ê°•ì„œêµ¬", "êµ¬ë¡œêµ¬", "ê¸ˆì²œêµ¬", "ì˜ë“±í¬êµ¬", "ë™ì‘êµ¬", "ê´€ì•…êµ¬", "ì„œì´ˆêµ¬",
             "ê°•ë‚¨êµ¬", "ì†¡íŒŒêµ¬", "ê°•ë™êµ¬"],
    "ë¶€ì‚°": ["ì¤‘êµ¬", "ì„œêµ¬", "ë™êµ¬", "ì˜ë„êµ¬", "ë¶€ì‚°ì§„êµ¬", "ë™ë˜êµ¬", "ë‚¨êµ¬", "ë¶êµ¬",
             "í•´ìš´ëŒ€êµ¬", "ì‚¬í•˜êµ¬", "ê¸ˆì •êµ¬", "ê°•ì„œêµ¬", "ì—°ì œêµ¬", "ìˆ˜ì˜êµ¬", "ì‚¬ìƒêµ¬",
             "ê¸°ì¥êµ°"],
    "ëŒ€êµ¬": ["ì¤‘êµ¬", "ë™êµ¬", "ì„œêµ¬", "ë‚¨êµ¬", "ë¶êµ¬", "ìˆ˜ì„±êµ¬", "ë‹¬ì„œêµ¬", "ë‹¬ì„±êµ°", "êµ°ìœ„êµ°"],
    "ì¸ì²œ": ["ê°•í™”êµ°", "ì˜¹ì§„êµ°", "ì¤‘êµ¬", "ë™êµ¬", "ë¯¸ì¶”í™€êµ¬", "ì—°ìˆ˜êµ¬", "ë‚¨ë™êµ¬",
             "ë¶€í‰êµ¬", "ê³„ì–‘êµ¬", "ì„œêµ¬"],
    "ê´‘ì£¼": ["ë™êµ¬", "ì„œêµ¬", "ë‚¨êµ¬", "ë¶êµ¬", "ê´‘ì‚°êµ¬"],
    "ëŒ€ì „": ["ë™êµ¬", "ì¤‘êµ¬", "ì„œêµ¬", "ìœ ì„±êµ¬", "ëŒ€ë•êµ¬"],
    "ìš¸ì‚°": ["ì¤‘êµ¬", "ë‚¨êµ¬", "ë™êµ¬", "ë¶êµ¬", "ìš¸ì£¼êµ°"],
    "ì„¸ì¢…": [],
    "ê²½ê¸°": ["ìˆ˜ì›ì‹œ", "ê³ ì–‘ì‹œ", "ìš©ì¸ì‹œ", "ì„±ë‚¨ì‹œ", "ë¶€ì²œì‹œ", "í™”ì„±ì‹œ", "ì•ˆì‚°ì‹œ",
             "ë‚¨ì–‘ì£¼ì‹œ", "ì•ˆì–‘ì‹œ", "í‰íƒì‹œ", "ì‹œí¥ì‹œ", "íŒŒì£¼ì‹œ", "ì˜ì •ë¶€ì‹œ",
             "ê¹€í¬ì‹œ", "ê´‘ì£¼ì‹œ", "ê´‘ëª…ì‹œ", "êµ°í¬ì‹œ", "í•˜ë‚¨ì‹œ", "ì˜¤ì‚°ì‹œ", "ì–‘ì£¼ì‹œ",
             "ì´ì²œì‹œ", "êµ¬ë¦¬ì‹œ", "ì•ˆì„±ì‹œ", "í¬ì²œì‹œ", "ì˜ì™•ì‹œ", "ì–‘í‰êµ°", "ì—¬ì£¼ì‹œ",
             "ë™ë‘ì²œì‹œ", "ê³¼ì²œì‹œ", "ê°€í‰êµ°", "ì—°ì²œêµ°"],
    "ê°•ì›": ["ì¶˜ì²œì‹œ", "ì›ì£¼ì‹œ", "ê°•ë¦‰ì‹œ", "ë™í•´ì‹œ", "íƒœë°±ì‹œ", "ì†ì´ˆì‹œ", "ì‚¼ì²™ì‹œ",
             "í™ì²œêµ°", "íš¡ì„±êµ°", "ì˜ì›”êµ°", "í‰ì°½êµ°", "ì •ì„ êµ°", "ì² ì›êµ°", "í™”ì²œêµ°",
             "ì–‘êµ¬êµ°", "ì¸ì œêµ°", "ê³ ì„±êµ°", "ì–‘ì–‘êµ°"],
    "ì¶©ë¶": ["ì²­ì£¼ì‹œ", "ì¶©ì£¼ì‹œ", "ì œì²œì‹œ", "ë³´ì€êµ°", "ì˜¥ì²œêµ°", "ì˜ë™êµ°", "ì¦í‰êµ°",
             "ì§„ì²œêµ°", "ê´´ì‚°êµ°", "ìŒì„±êµ°", "ë‹¨ì–‘êµ°"],
    "ì¶©ë‚¨": ["ì²œì•ˆì‹œ", "ê³µì£¼ì‹œ", "ë³´ë ¹ì‹œ", "ì•„ì‚°ì‹œ", "ì„œì‚°ì‹œ", "ë…¼ì‚°ì‹œ", "ê³„ë£¡ì‹œ",
             "ë‹¹ì§„ì‹œ", "ê¸ˆì‚°êµ°", "ë¶€ì—¬êµ°", "ì„œì²œêµ°", "ì²­ì–‘êµ°", "í™ì„±êµ°", "ì˜ˆì‚°êµ°",
             "íƒœì•ˆêµ°"],
    "ì „ë¶": ["ì „ì£¼ì‹œ", "êµ°ì‚°ì‹œ", "ìµì‚°ì‹œ", "ì •ìì‹œ", "ë‚¨ì›ì‹œ", "ê¹€ì œì‹œ", "ì™„ì£¼êµ°",
             "ì§„ì•ˆêµ°", "ë¬´ì£¼êµ°", "ì¥ìˆ˜êµ°", "ì„ì‹¤êµ°", "ìˆœì°½êµ°", "ê³ ì°½êµ°", "ë¶€ì•ˆêµ°"],
    "ì „ë‚¨": ["ëª©í¬ì‹œ", "ì—¬ìˆ˜ì‹œ", "ìˆœì²œì‹œ", "ë‚˜ì£¼ì‹œ", "ê´‘ì–‘ì‹œ", "ë‹´ì–‘êµ°", "ê³¡ì„±êµ°",
             "êµ¬ë¡€êµ°", "ê³ í¥êµ°", "ë³´ì„±êµ°", "í™”ìˆœêµ°", "ì¥í¥êµ°", "ê°•ì§„êµ°", "í•´ë‚¨êµ°",
             "ì˜ì•”êµ°", "ë¬´ì•ˆêµ°", "í•¨í‰êµ°", "ì˜ê´‘êµ°", "ì¥ì„±êµ°", "ì™„ë„êµ°", "ì§„ë„êµ°",
             "ì‹ ì•ˆêµ°"],
    "ê²½ë¶": ["í¬í•­ì‹œ", "ê²½ì£¼ì‹œ", "ê¹€ì²œì‹œ", "ì•ˆë™ì‹œ", "êµ¬ë¯¸ì‹œ", "ì˜ì£¼ì‹œ", "ì˜ì²œì‹œ",
             "ìƒì£¼ì‹œ", "ë¬¸ê²½ì‹œ", "ê²½ì‚°ì‹œ", "ì˜ì„±êµ°", "ì²­ì†¡êµ°", "ì˜ì–‘êµ°", "ì˜ë•êµ°",
             "ì²­ë„êµ°", "ê³ ë ¹êµ°", "ì„±ì£¼êµ°", "ì¹ ê³¡êµ°", "ì˜ˆì²œêµ°", "ë´‰í™”êµ°", "ìš¸ì§„êµ°",
             "ìš¸ë¦‰êµ°"],
    "ê²½ë‚¨": ["ì°½ì›ì‹œ", "ì§„ì£¼ì‹œ", "í†µì˜ì‹œ", "ì‚¬ì²œì‹œ", "ê¹€í•´ì‹œ", "ë°€ì–‘ì‹œ", "ê±°ì œì‹œ",
             "ì–‘ì‚°ì‹œ", "ì˜ë ¹êµ°", "í•¨ì•ˆêµ°", "ì°½ë…•êµ°", "ê³ ì„±êµ°", "ë‚¨í•´êµ°", "í•˜ë™êµ°",
             "ì‚°ì²­êµ°", "í•¨ì–‘êµ°", "ê±°ì°½êµ°", "í•©ì²œêµ°"],
    "ì œì£¼": ["ì œì£¼ì‹œ", "ì„œê·€í¬ì‹œ"]
}

############################
# 3) Streamlit ê¸°ë³¸ UI
############################
st.title("ğŸ’¬ ë§ì¶¤í˜• ì±„ìš© ê³µê³  ì¶”ì²œ ì±—ë´‡")

############################
# 'ë§ì¶¤í˜• ì±„ìš© ê³µê³  ì¶”ì²œ' UI
############################
if st.session_state["selected_tab"] == "job_recommendation":
    st.subheader("ğŸ‘ ì§€ì›ìë‹˜ì˜ ìš”ì²­ ì‚¬í•­ì— ë§ëŠ” ê³µê³ ë“¤ì„ ì¶”ì²œí•´ë“œë ¤ìš”.")
    st.subheader("""
    ğŸ“Œ **ì±„íŒ… ì…ë ¥ì‹œ ì•ˆë‚´ì‚¬í•­**

    ì…ë ¥í•˜ì‹¤ ë•Œ ë¶ˆí™•ì‹¤í•˜ê±°ë‚˜ ëª¨í˜¸í•œ ë¶€ë¶„ì´ ìˆì–´ë„ ê±±ì •í•˜ì§€ ë§ˆì„¸ìš”!  
    í•´ë‹¹ ë‚´ìš©ì€ ìƒëµí•˜ì…”ë„ ê´œì°®ìœ¼ë©°, ì œê³µí•´ì£¼ì‹  ì •ë³´ë§Œìœ¼ë¡œë„ ìµœì ì˜ ì±„ìš© ê³µê³ ë¥¼ ì¶”ì²œí•´ë“œë¦´ê²Œìš”.
    """)

    # (1) ì§€ì› ì§ë¬´(ê³µê³ ì œëª©)
    job_title = st.text_input("1ï¸âƒ£ ì§€ì›í•˜ê³ ì í•˜ëŠ” ì§ë¬´ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.", placeholder="ì˜ˆ) ë°ì´í„° ë¶„ì„ê°€")
    # â€» 'ê³µê³ ì œëª© ì¤‘ìš”ë„'ëŠ” ë” ì´ìƒ ë°›ì§€ ì•ŠìŒ

    # (2) ê²½ë ¥
    experience = st.slider("2ï¸âƒ£ ì§€ì›í•˜ê³ ì í•˜ëŠ” ë¶„ì•¼ì™€ ê´€ë ¨ëœ ê²½ë ¥(ê·¼ë¬´ ì—°ìˆ˜)ì„ ì„ íƒí•´ì£¼ì„¸ìš”.", 0, 20, 0)

    # (3) ê·¼ë¬´ ì‹œ/ë„ ì„ íƒ
    if st.session_state["selected_sido"] == ["ì „ì²´"]:
        sido_options = ["ì „ì²´"]
        default_vals = ["ì „ì²´"]
    else:
        sido_options = ["ì „ì²´"] + list(location_dict.keys())
        default_vals = st.session_state["selected_sido"]

    def update_sido_selection():
        current_sido = st.session_state["selected_sido_widget"]
        if "ì „ì²´" in current_sido:
            st.session_state["selected_sido"] = ["ì „ì²´"]
        else:
            st.session_state["selected_sido"] = [s for s in current_sido if s in location_dict]

    st.multiselect(
        "3ï¸âƒ£ ì›í•˜ì‹œëŠ” ê·¼ë¬´ ìœ„ì¹˜(ì‹œ/ë„)ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.",
        options=sido_options,
        default=default_vals,
        key="selected_sido_widget",
        on_change=update_sido_selection
    )

    # (4) ì‹œ/êµ°/êµ¬ ì„ íƒ
    selected_sigungu = []
    if st.session_state["selected_sido"] == ["ì „ì²´"]:
        for sido_key, sigungu_list in location_dict.items():
            if sido_key == "ì„¸ì¢…":
                selected_sigungu.append("ì„¸ì¢…")
            else:
                for sg in sigungu_list:
                    selected_sigungu.append(f"{sido_key} {sg}")
    else:
        for sido in st.session_state["selected_sido"]:
            if sido == "ì„¸ì¢…":
                selected_sigungu.append("ì„¸ì¢…")
                continue

            sigungu_key = f"selected_sigungu_{sido}"
            widget_key = f"{sigungu_key}_widget"

            if sigungu_key not in st.session_state:
                st.session_state[sigungu_key] = []

            def make_sigungu_callback(sido_=sido):
                def _cb():
                    current_ = st.session_state[widget_key]
                    if "ì „ì²´" in current_:
                        st.session_state[sigungu_key] = ["ì „ì²´"]
                    else:
                        st.session_state[sigungu_key] = [
                            sg for sg in current_ if sg in location_dict[sido_]
                        ]
                return _cb

            if st.session_state[sigungu_key] == ["ì „ì²´"]:
                this_options = ["ì „ì²´"]
                this_defaults = ["ì „ì²´"]
            else:
                this_options = ["ì „ì²´"] + location_dict[sido]
                this_defaults = st.session_state[sigungu_key]

            st.multiselect(
                f"ğŸ“ {sido}ì˜ ì‹œ/êµ°/êµ¬ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.",
                options=this_options,
                default=this_defaults,
                key=widget_key,
                on_change=make_sigungu_callback(sido)
            )

        for sido in st.session_state["selected_sido"]:
            if sido == "ì„¸ì¢…":
                continue
            sigungu_key = f"selected_sigungu_{sido}"
            if sigungu_key not in st.session_state:
                continue

            if st.session_state[sigungu_key] == ["ì „ì²´"]:
                for sg in location_dict[sido]:
                    selected_sigungu.append(f"{sido} {sg}")
            else:
                for sg in st.session_state[sigungu_key]:
                    selected_sigungu.append(f"{sido} {sg}")

    # (5) ì›í•˜ëŠ” ì—…ë¬´(ì£¼ìš”ì—…ë¬´)
    job_task = st.text_area("4ï¸âƒ£ ì›í•˜ì‹œëŠ” ì—…ë¬´ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.", placeholder="ì˜ˆ) ì €ëŠ” ë°ì´í„° ë¶„ì„ ë° ì‹œê°í™”ë¥¼ í•˜ê³  ì‹¶ì–´ìš”.")
    job_task_importance = (
        st.slider("â­ï¸ ì¤‘ìš”ë„", 1, 5, 3, key="job_task_importance") if job_task else None
    )

    # (6) ë³¸ì¸ì˜ ìŠ¤í‚¬ ë° í™œìš© ê°€ëŠ¥í•œ íˆ´ (ìê²©ìš”ê±´ ë° ìš°ëŒ€ì‚¬í•­)
    job_skills = st.text_area("5ï¸âƒ£ ë³¸ì¸ì˜ ìŠ¤í‚¬ ë° í™œìš© ê°€ëŠ¥í•œ íˆ´ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.", placeholder="ì˜ˆ) Pythonê³¼ SQLì„ ì˜í•´ìš”.")
    job_skills_importance = (
        st.slider("â­ï¸ ì¤‘ìš”ë„", 1, 5, 3, key="job_skills_importance") if job_skills else None
    )

    # (7) ì›í•˜ì‹œëŠ” í˜œíƒ ë° ë³µì§€
    job_benefits = st.text_area("6ï¸âƒ£ ì›í•˜ì‹œëŠ” í˜œíƒ ë° ë³µì§€ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.", placeholder="ì˜ˆ) ìœ ì—°ê·¼ë¬´ê°€ ê°€ëŠ¥í–ˆìœ¼ë©´ ì¢‹ê² ì–´ìš”")
    job_benefits_importance = (
        st.slider("â­ï¸ ì¤‘ìš”ë„", 1, 5, 3, key="job_benefits_importance") if job_benefits else None
    )

    # =========================
    # ğŸš€ ì œì¶œ ë²„íŠ¼
    # =========================
    if st.button("ğŸš€ ë‹µë³€ ì œì¶œ"):
        ####################################################################
        # A) ì‚¬ìš©ì ì…ë ¥ êµ¬ì¡°í™”: ê²½ë ¥, ê·¼ë¬´ìœ„ì¹˜ => í•˜ë“œí•„í„°
        #    (ì£¼ìš”ì—…ë¬´, ìê²©ìš”ê±´ë°ìš°ëŒ€ì‚¬í•­, í˜œíƒë°ë³µì§€) => ì†Œí”„íŠ¸í•„í„°
        #    (ê³µê³ ì œëª©) => ë³„ë„ ë¡œì§
        ####################################################################
        hard_filter_dict = {
            "ê²½ë ¥": experience,
            "ê·¼ë¬´ìœ„ì¹˜": selected_sigungu
        }

        # ì†Œí”„íŠ¸í•„í„°(ì£¼ìš”ì—…ë¬´, ìê²©ìš”ê±´ë°ìš°ëŒ€ì‚¬í•­, í˜œíƒë°ë³µì§€)ë§Œ dictì— ë‹´ìŒ
        # ê³µê³ ì œëª©ì€ ì—¬ê¸° ì•ˆ ë„£ìŒ
        soft_filters = []
        if job_task and job_task_importance is not None:
            soft_filters.append(("ì£¼ìš”ì—…ë¬´", [job_task.strip()], job_task_importance))
        if job_skills and job_skills_importance is not None:
            # "ìê²©ìš”ê±´ë°ìš°ëŒ€ì‚¬í•­" ì»¬ëŸ¼ì— ë§¤ì¹­
            soft_filters.append(("ìê²©ìš”ê±´ë°ìš°ëŒ€ì‚¬í•­", [job_skills.strip()], job_skills_importance))
        if job_benefits and job_benefits_importance is not None:
            soft_filters.append(("í˜œíƒë°ë³µì§€", [job_benefits.strip()], job_benefits_importance))

        total_importance = sum([f[2] for f in soft_filters])
        soft_filter_dict = {}
        if total_importance > 0:
            for col_name, kw_list, imp in soft_filters:
                weight = round(imp / total_importance, 4)
                soft_filter_dict[col_name] = {
                    "ê°€ì¤‘ì¹˜": weight,
                    "ì¡°ê±´": kw_list
                }
                
        user_input_json = {"soft_filter": soft_filter_dict}

        # job_titleì€ ë³„ë„ë¡œ ë³´ê´€
        job_title_input = job_title.strip()
        
        print("=== [Debug] user_input_json ===")
        print(user_input_json)
        print("=== [Debug] hard_filter ===")
        print(hard_filter_dict)
        print("=== [Debug] soft_filter_dict ===")
        print(json.dumps(soft_filter_dict, ensure_ascii=False, indent=2))
        print("=== [Debug] job_title_input ===", job_title_input)
        print("===========================================")

        ####################################################################
        # B) ChromaDB ì—°ê²° ë° ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
        ####################################################################
        # ì„ë² ë”© ëª¨ë¸ íƒ€ì…: "bge" ë˜ëŠ” "jina"
        embedding_model_type = "bge"  # ì˜ˆ: bge ì‚¬ìš©

        if embedding_model_type == "bge":
            db_path = "./chroma_db_bge"
            bge_model = BGEM3FlagModel(
                'BAAI/bge-m3',
                use_fp16=False,   # CPUë¼ë©´ False ê¶Œì¥
                device="cpu"
            )
            def embed_with_model(text: str):
                if not text.strip():
                    text = " "
                out = bge_model.encode(
                    [text],
                    max_length=1024,
                    return_dense=True,
                    return_sparse=False,
                    return_colbert_vecs=False
                )
                return out["dense_vecs"][0]
        else:
            db_path = "./chroma_db_jina"
            jina_model = JinaEmbeddingModel(
                model_name="jinaai/jina-embeddings-v3",
                use_fp16=False,   # CPU
                task="text-matching"
            )
            def embed_with_model(text: str):
                if not text.strip():
                    text = " "
                out = jina_model.encode(
                    [text],
                    max_length=1024
                )
                return out["dense_vecs"][0]

        def cosine_similarity(vec1, vec2):
            dot = np.dot(vec1, vec2)
            norm1 = np.linalg.norm(vec1)
            norm2 = np.linalg.norm(vec2)
            if norm1 == 0 or norm2 == 0:
                return 0.0
            return float(dot / (norm1 * norm2))

        # ChromaDB Client & Collection
        client_chroma = chromadb.PersistentClient(path=db_path)
        collection_name = "job_postings_collection"
        try:
            collection = client_chroma.get_collection(collection_name)
        except:
            st.error("ChromaDB ì»¬ë ‰ì…˜ì´ ì¡´ì¬í•˜ì§€ ì•Šì•„ìš”.")
            st.stop()

        ####################################################################
        # C) í•˜ë“œí•„í„° (ê²½ë ¥, ê·¼ë¬´ìœ„ì¹˜) -> ChromaDB Where ì¡°ê±´
        ####################################################################
        hard_exp = float(hard_filter_dict["ê²½ë ¥"])
        hard_locs = hard_filter_dict["ê·¼ë¬´ìœ„ì¹˜"]

        and_conditions = []
        # (1) ê²½ë ¥ ì¡°ê±´
        and_conditions.append({"ê²½ë ¥": {"$lte": hard_exp}})

        # (2) ê·¼ë¬´ìœ„ì¹˜ ì¡°ê±´
        if "ì „ì²´" not in hard_locs and len(hard_locs) > 0:
            and_conditions.append({"ê·¼ë¬´ìœ„ì¹˜": {"$in": hard_locs}})

        if len(and_conditions) == 1:
            where_clause = and_conditions[0]
        elif len(and_conditions) > 1:
            where_clause = {"$and": and_conditions}
        else:
            where_clause = {}

        filtered_docs = collection.get(
            where=where_clause,
            include=["embeddings", "metadatas"],
            limit=999999
        )

        if len(filtered_docs["ids"]) == 0:
            st.warning("ê²½ë ¥ ë° ê·¼ë¬´ìœ„ì¹˜ ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ê³µê³ ê°€ ì—†ì–´ìš”.")
            st.stop()

        ####################################################################
        # D) ê³µê³ ì œëª© + ë‚˜ë¨¸ì§€ ì†Œí”„íŠ¸í•„í„° ë¡œì§ ë¶„ê¸°
        ####################################################################
        # - Case A: job_titleë§Œ ìˆê³  (job_task, job_skills, job_benefits)ëŠ” ì—†ìŒ
        # - Case B: job_title + (job_task ë˜ëŠ” job_skills ë˜ëŠ” job_benefits ì¤‘ í•˜ë‚˜ ì´ìƒ) ì¡´ì¬
        # - Case C: job_titleì´ ì—†ê³ , ë‚˜ë¨¸ì§€ ì†Œí”„íŠ¸í•„í„°ê°€ ìˆëŠ” ê²½ìš°
        # - Case D: job_titleì´ ì—†ê³ , ë‚˜ë¨¸ì§€ ì†Œí”„íŠ¸í•„í„°ë„ ì—†ëŠ” ê²½ìš°
        ####################################################################

        has_job_title = bool(job_title_input)
        has_job_task = bool(job_task.strip())
        has_job_skills = bool(job_skills.strip())
        has_job_benefits = bool(job_benefits.strip())

        soft_filter_count = sum([has_job_task, has_job_skills, has_job_benefits])

        # ================================
        # D-1) ìœ í‹¸: ìµœì¢… ê³µê³  í‘œì‹œ í•¨ìˆ˜
        # ================================
        def display_partial_text(label: str, text: str, char_limit=100):
            if not text or pd.isna(text):
                st.markdown(f"**{label}:** ë‚´ìš©ì´ ê²Œì‹œë˜ì–´ ìˆì§€ ì•Šì•„ìš”!")
                return
            text = apply_indentation(text)
            if len(text) <= char_limit:
                st.markdown(f"**{label}:**")
                st.text(text)
            else:
                truncated = text[:char_limit] + "..."
                st.markdown(f"**{label}:**")
                st.text(truncated)
                with st.expander("ìƒì„¸ ë³´ê¸°"):
                    st.text(text)

        def apply_indentation(text):
            lines = text.split('\n')
            indented_lines = []
            for line in lines:
                if any(line.strip().startswith(marker) for marker in INDENTATION_MARKERS):
                    indented_lines.append(f"    {line.strip()}")
                else:
                    indented_lines.append(line)
            return '\n'.join(indented_lines)

        def show_job_postings(final_df):
            for idx, (_, row) in enumerate(final_df.iterrows(), start=1):
                st.markdown(f"### Top {idx}: {row['ê³µê³ ì œëª©']}")
                st.markdown(f"**íšŒì‚¬ëª…:** {row['íšŒì‚¬ëª…']}")
                display_partial_text("ì£¼ìš” ì—…ë¬´", row.get("ì£¼ìš”ì—…ë¬´", ""))
                display_partial_text("ìê²© ìš”ê±´", row.get("ìê²©ìš”ê±´", ""))
                display_partial_text("ìš°ëŒ€ ì‚¬í•­", row.get("ìš°ëŒ€ì‚¬í•­", ""))
                display_partial_text("í˜œíƒ ë° ë³µì§€", row.get("í˜œíƒë°ë³µì§€", ""))
                st.markdown(f"**ê·¼ë¬´ ìœ„ì¹˜:** {row.get('ê·¼ë¬´ìœ„ì¹˜','')}")
                exp_str = "ì‹ ì…" if int(row.get("ê²½ë ¥",0)) == 0 else f"{int(row.get('ê²½ë ¥',0))}ë…„ ì´ìƒ"
                st.markdown(f"**ê²½ë ¥:** {exp_str}")
                st.markdown(f"**ìµœì¢… ì ìˆ˜:** {row.get('ìµœì¢…ì ìˆ˜','0.0')}")
                url_val = row.get("ê³µê³ ìƒì„¸url", "")
                if pd.notna(url_val) and url_val:
                    st.markdown(f"**URL:** [ë°”ë¡œê°€ê¸°]({url_val})")
                st.markdown("---")

        # ==============================================
        # D-2) â€œì†Œí”„íŠ¸í•„í„°â€ (ì£¼ìš”ì—…ë¬´, ìê²©ìš”ê±´ë°ìš°ëŒ€ì‚¬í•­, í˜œíƒë°ë³µì§€) ê³„ì‚° í•¨ìˆ˜
        # ==============================================
        def calc_soft_filter_scores(docs, user_filter_dict):
            """
            docs: í•˜ë“œí•„í„°ë¥¼ í†µê³¼í•˜ê³  (ê³µê³ ì œëª©ì´ë“  ì£¼ìš”ì—…ë¬´ë“  ì „ë¶€) ê°€ì ¸ì˜¨ ChromaDB ë¬¸ì„œë“¤.
            user_filter_dict: {"ì£¼ìš”ì—…ë¬´": {...}, "ìê²©ìš”ê±´ë°ìš°ëŒ€ì‚¬í•­": {...}, "í˜œíƒë°ë³µì§€": {...}}
            (ê°€ì¤‘ì¹˜, ì¡°ê±´) êµ¬ì¡°
            """
            # 1) ê° í•„ë“œë³„ ì‚¬ìš©ì ì„ë² ë”©
            keyword_embeddings = {}
            for col_type, info in user_filter_dict.items():
                emb_list = []
                for kw in info["ì¡°ê±´"]:
                    emb_list.append(embed_with_model(kw))
                keyword_embeddings[col_type] = emb_list

            # 2) job_idë³„ raw ìœ ì‚¬ë„
            sim_raw = {}
            for i, doc_id in enumerate(docs["ids"]):
                emb = np.array(docs["embeddings"][i], dtype=np.float32)
                meta = docs["metadatas"][i]
                j_id = meta["ê³µê³ id"]
                t = meta["type"]

                if j_id not in sim_raw:
                    sim_raw[j_id] = {}

                # ì´ docì˜ typeì´ user_filter_dictì— ìˆë‹¤ë©´
                if t in user_filter_dict:
                    kw_embs = keyword_embeddings[t]
                    if len(kw_embs) == 0:
                        raw_sim = 0.0
                    else:
                        # ì‚¬ìš©ì ì…ë ¥ë¬¸ ì—¬ëŸ¬ ê°œë©´ í‰ê· 
                        scores = []
                        for kw_vec in kw_embs:
                            s = cosine_similarity(emb, kw_vec)
                            scores.append(s)
                        raw_sim = np.mean(scores) if scores else 0.0
                    sim_raw[j_id][t] = raw_sim

            # 3) ìµœì¢… ì ìˆ˜ (ê°€ì¤‘í•©)
            final_scores = {}
            for j_id in sim_raw.keys():
                score_sum = 0.0
                for doc_type, info in user_filter_dict.items():
                    raw_val = sim_raw[j_id].get(doc_type, 0.0)
                    weight = info["ê°€ì¤‘ì¹˜"]
                    score_sum += raw_val * weight
                final_scores[j_id] = score_sum

            return final_scores

        # ======================================================
        # D-3) í•˜ë“œí•„í„° í†µê³¼í•œ ë¬¸ì„œë“¤ ì¤‘ì—ì„œ job_id ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ
        # ======================================================
        all_job_ids = []
        for meta in filtered_docs["metadatas"]:
            j_id = meta["ê³µê³ id"]
            if j_id not in all_job_ids:
                all_job_ids.append(j_id)

        # ======================================================
        # D-4) ìƒí™©ë³„ ë¶„ê¸°
        # ======================================================
        if has_job_title and soft_filter_count == 0:
            # --------------------------------------------------
            # Case A: ê³µê³ ì œëª© "ë‹¨ë…"
            # => "ê²½ë ¥,ê·¼ë¬´ìœ„ì¹˜" í•˜ë“œí•„í„° í†µê³¼í•œ docs ì¤‘ "type=ê³µê³ ì œëª©"ê³¼ì˜ ìœ ì‚¬ë„ => top5
            # --------------------------------------------------
            title_vec = embed_with_model(job_title_input)

            # typeì´ "ê³µê³ ì œëª©"ì¸ ë¬¸ì„œë§Œ ê³¨ë¼ì„œ ìœ ì‚¬ë„ ê³„ì‚°
            doc_scores = {}
            for i, doc_id in enumerate(filtered_docs["ids"]):
                meta = filtered_docs["metadatas"][i]
                t = meta["type"]
                j_id = meta["ê³µê³ id"]
                if t == "ê³µê³ ì œëª©":
                    emb = np.array(filtered_docs["embeddings"][i], dtype=np.float32)
                    sim = cosine_similarity(title_vec, emb)
                    doc_scores[j_id] = sim

            if not doc_scores:
                st.warning("ê³µê³ ì œëª© ì„ë² ë”©ì„ ê³„ì‚°í–ˆì§€ë§Œ, í•´ë‹¹ íƒ€ì… ë¬¸ì„œê°€ ì—†ì–´ìš”.")
                st.stop()

            # ì ìˆ˜ ê¸°ì¤€ top5
            sorted_ids = sorted(doc_scores.keys(), key=lambda x: doc_scores[x], reverse=True)[:5]

            # all_raw.xlsxì—ì„œ í•´ë‹¹ ê³µê³  ì„¸ë¶€ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ê¸°
            df_all = pd.read_excel("./all_raw.xlsx")
            df_all["ê³µê³ id"] = df_all["ê³µê³ id"].astype(str)

            top_df = df_all[df_all["ê³µê³ id"].isin(sorted_ids)].copy()
            top_df["ìµœì¢…ì ìˆ˜"] = top_df["ê³µê³ id"].apply(lambda x: round(doc_scores.get(str(x), 0.0), 4))
            top_df = top_df.sort_values("ìµœì¢…ì ìˆ˜", ascending=False)

            if len(top_df) == 0:
                st.warning("ê³µê³ ì œëª© ìœ ì‚¬ë„ ê¸°ë°˜ ì¶”ì²œ ê²°ê³¼ê°€ ì—†ì–´ìš”.")
                st.stop()

            st.success("ğŸ” ì‘ì„±í•˜ì‹  ì§ë¬´ ê¸°ë°˜ ìƒìœ„ 5ê°œ ê³µê³ ë¥¼ ë³´ì—¬ë“œë ¤ìš”!")
            show_job_postings(top_df)

        elif has_job_title and soft_filter_count > 0:
            # --------------------------------------------------
            # Case B: ê³µê³ ì œëª© + (ì£¼ìš”ì—…ë¬´ or ìê²©ìš”ê±´ or í˜œíƒ ë“±) 1ê°œ ì´ìƒ
            # => 2ë‹¨ê³„ í•˜ë“œí•„í„°(ê³µê³ ì œëª© ìœ ì‚¬ë„ â‰¥ 0.6) -> ì†Œí”„íŠ¸í•„í„°
            # --------------------------------------------------
            title_vec = embed_with_model(job_title_input)

            # (1) ê³µê³ ì œëª© ìœ ì‚¬ë„ê°€ ì¼ì • threshold ì´ìƒì¸ ê³µê³ ë§Œ ë‚¨ê¹€
            pass_ids = []
            for i, doc_id in enumerate(filtered_docs["ids"]):
                meta = filtered_docs["metadatas"][i]
                t = meta["type"]
                j_id = meta["ê³µê³ id"]
                if t == "ê³µê³ ì œëª©":
                    emb = np.array(filtered_docs["embeddings"][i], dtype=np.float32)
                    sim = cosine_similarity(title_vec, emb)
                    if sim >= 0.4:
                        if j_id not in pass_ids:
                            pass_ids.append(j_id)

            if not pass_ids:
                st.warning("ì§ë¬´ ì¡°ê±´ì˜ thresholdë¥¼ ë§Œì¡±í•˜ëŠ” ê³µê³ ê°€ ì—†ìŠµë‹ˆë‹¤.")
                st.stop()

            # (2) pass_idsì— ì†í•œ ë¬¸ì„œë§Œ ë‹¤ì‹œ ëª¨ì•„ì„œ -> ì†Œí”„íŠ¸í•„í„°(ì£¼ìš”ì—…ë¬´, ìê²©ìš”ê±´, í˜œíƒ ë“±) ê³„ì‚°
            pass_docs_ids = []
            pass_docs_embeddings = []
            pass_docs_metas = []

            for i, doc_id in enumerate(filtered_docs["ids"]):
                meta = filtered_docs["metadatas"][i]
                j_id = meta["ê³µê³ id"]
                if j_id in pass_ids:
                    pass_docs_ids.append(doc_id)
                    pass_docs_embeddings.append(filtered_docs["embeddings"][i])
                    pass_docs_metas.append(meta)

            # ì¬êµ¬ì„±í•œ docs dict
            pass_docs = {
                "ids": pass_docs_ids,
                "embeddings": pass_docs_embeddings,
                "metadatas": pass_docs_metas
            }

            if len(soft_filter_dict) == 0:
                # ë§Œì•½ ì†Œí”„íŠ¸í•„í„°ê°€ í•˜ë‚˜ë„ ì—†ë‹¤ë©´ => í†µê³¼í•œ ê³µê³  ì¤‘ ìƒìœ„ 5ê°œ ê·¸ëƒ¥ ë°˜í™˜
                # (í•˜ì§€ë§Œ ì´ë¯¸ has_job_title and soft_filter_count>0 ë¼ì„œ ì—¬ê¸°ì„  ë°œìƒí•˜ì§€ ì•Šê² ì§€ë§Œ í˜¹ì‹œ ëª¨ë¥¼ ëŒ€ë¹„)
                job_ids = []
                for meta in pass_docs["metadatas"]:
                    j_id = meta["ê³µê³ id"]
                    if j_id not in job_ids:
                        job_ids.append(j_id)
                top5_ids = job_ids[:5]
                df_all = pd.read_excel("./all_raw.xlsx")
                df_all["ê³µê³ id"] = df_all["ê³µê³ id"].astype(str)
                filtered_df = df_all[df_all["ê³µê³ id"].isin(top5_ids)].copy()
                filtered_df["ìµœì¢…ì ìˆ˜"] = 0.0
                show_job_postings(filtered_df)
                st.stop()
            else:
                # ì†Œí”„íŠ¸í•„í„° ê³„ì‚°
                final_scores = calc_soft_filter_scores(pass_docs, soft_filter_dict)
                if not final_scores:
                    st.warning("ì†Œí”„íŠ¸í•„í„° ì ìˆ˜ë¥¼ ê³„ì‚°í•  ë¬¸ì„œê°€ ì—†ì–´ìš”.")
                    st.stop()
                # top5
                sorted_ids = sorted(final_scores.keys(), key=lambda x: final_scores[x], reverse=True)[:5]
                if not sorted_ids:
                    st.warning("ì†Œí”„íŠ¸í•„í„°ë¥¼ ë§Œì¡±í•˜ëŠ” ìƒìœ„ ê³µê³ ê°€ ì—†ì–´ìš”.")
                    st.stop()

                df_all = pd.read_excel("./all_raw.xlsx")
                df_all["ê³µê³ id"] = df_all["ê³µê³ id"].astype(str)
                top_df = df_all[df_all["ê³µê³ id"].isin(sorted_ids)].copy()
                top_df["ìµœì¢…ì ìˆ˜"] = top_df["ê³µê³ id"].apply(lambda x: round(final_scores.get(str(x), 0.0), 4))
                top_df = top_df.sort_values("ìµœì¢…ì ìˆ˜", ascending=False)

                st.success("ğŸ” ë§ì¶¤í˜• ê³µê³  ìƒìœ„ 5ê°œë¥¼ ë³´ì—¬ë“œë ¤ìš”!")
                show_job_postings(top_df)

        else:
            # --------------------------------------------------
            # ê³µê³ ì œëª©ì´ ì—†ëŠ” ê²½ìš° -> Case C, D
            # Case C: ì†Œí”„íŠ¸í•„í„°(ì£¼ìš”ì—…ë¬´,ìê²©ìš”ê±´,í˜œíƒ) ì¡´ì¬
            # Case D: ì†Œí”„íŠ¸í•„í„°ë„ ì—†ìŒ
            # --------------------------------------------------
            if len(soft_filter_dict) == 0:
                # Case D: ì†Œí”„íŠ¸í•„í„° ì „ë¬´
                job_ids = []
                for meta in filtered_docs["metadatas"]:
                    j_id = meta["ê³µê³ id"]
                    if j_id not in job_ids:
                        job_ids.append(j_id)
                top5 = job_ids[:5]

                df_all = pd.read_excel("./all_raw.xlsx")
                df_all["ê³µê³ id"] = df_all["ê³µê³ id"].astype(str)
                filtered_df = df_all[df_all["ê³µê³ id"].isin(top5)].copy()
                filtered_df["ìµœì¢…ì ìˆ˜"] = 0.0
                show_job_postings(filtered_df)
            else:
                # Case C: ê³µê³ ì œëª©ì€ ì—†ê³ , ì†Œí”„íŠ¸í•„í„° ì¡´ì¬
                final_scores = calc_soft_filter_scores(filtered_docs, soft_filter_dict)
                if not final_scores:
                    st.warning("ì†Œí”„íŠ¸í•„í„° ì ìˆ˜ë¥¼ ê³„ì‚°í•  ë¬¸ì„œê°€ ì—†ì–´ìš”.")
                    st.stop()
                sorted_ids = sorted(final_scores.keys(), key=lambda x: final_scores[x], reverse=True)[:5]
                if not sorted_ids:
                    st.warning("ì†Œí”„íŠ¸í•„í„° ê²°ê³¼, ìƒìœ„ ê³µê³ ê°€ ì—†ì–´ìš”.")
                    st.stop()

                df_all = pd.read_excel("./all_raw.xlsx")
                df_all["ê³µê³ id"] = df_all["ê³µê³ id"].astype(str)
                top_df = df_all[df_all["ê³µê³ id"].isin(sorted_ids)].copy()
                top_df["ìµœì¢…ì ìˆ˜"] = top_df["ê³µê³ id"].apply(lambda x: round(final_scores.get(str(x), 0.0), 4))
                top_df = top_df.sort_values("ìµœì¢…ì ìˆ˜", ascending=False)

                st.success("ğŸ” ë§ì¶¤í˜• ê³µê³  ìƒìœ„ 5ê°œë¥¼ ë³´ì—¬ë“œë ¤ìš”!")
                show_job_postings(top_df)

        ######################################################
        # ì¶”ê°€: ì¶”ì²œ ì‚¬ìœ ë¥¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜ ì •ì˜ (ê³µê³ ì œëª©ì€ ì œì™¸)
        ######################################################
        def generate_recommendation_rationale(user_input_json, top_df):
            provided_fields = [key for key in user_input_json["soft_filter"].keys()]
        
            # í”„ë¡¬í”„íŠ¸ ì´ˆê¸° êµ¬ì„±
            prompt = "ì•„ë˜ëŠ” ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì†Œí”„íŠ¸ í•„í„° ì •ë³´ì™€ ì¶”ì²œëœ Top 5 ê³µê³ ì˜ ì£¼ìš” ë‚´ìš©ì…ë‹ˆë‹¤.\n\n"
        
            # ì‚¬ìš©ì ì…ë ¥ (ì†Œí”„íŠ¸ í•„í„°)
            prompt += "ì‚¬ìš©ì ì…ë ¥ (ì†Œí”„íŠ¸ í•„í„°):\n"
            for key in provided_fields:
                if key == "ìê²©ìš”ê±´ë°ìš°ëŒ€ì‚¬í•­":
                    prompt += f"- ìê²©ìš”ê±´ë°ìš°ëŒ€ì‚¬í•­ (ìê²©ìš”ê±´ ë° ìš°ëŒ€ì‚¬í•­ ëª¨ë‘ í•´ë‹¹): {user_input_json['soft_filter'][key]['ì¡°ê±´']}\n"
                else:
                    prompt += f"- {key}: {user_input_json['soft_filter'][key]['ì¡°ê±´']}\n"
        
            # ì¶”ì²œëœ ì±„ìš© ê³µê³  ë‚´ìš© - Top ìˆœì„œëŒ€ë¡œ
            prompt += "\nì¶”ì²œëœ ì±„ìš© ê³µê³  ë‚´ìš©:\n"
            for i, (_, row) in enumerate(top_df.iterrows(), start=1):
                prompt += f"Top {i}: **{row['ê³µê³ ì œëª©']}**\n"
                if "ì£¼ìš”ì—…ë¬´" in provided_fields:
                    prompt += f"  - **ì£¼ìš”ì—…ë¬´:** {row['ì£¼ìš”ì—…ë¬´']}\n\n"
                if "ìê²©ìš”ê±´ë°ìš°ëŒ€ì‚¬í•­" in provided_fields:
                    prompt += f"  - **ìê²©ìš”ê±´:** {row.get('ìê²©ìš”ê±´', '')}\n\n"
                    prompt += f"  - **ìš°ëŒ€ì‚¬í•­:** {row.get('ìš°ëŒ€ì‚¬í•­', '')}\n\n"
                if "í˜œíƒë°ë³µì§€" in provided_fields:
                    prompt += f"  - **í˜œíƒë°ë³µì§€:** {row['í˜œíƒë°ë³µì§€']}\n\n"
                prompt += "\n---\n\n"
        
            # ì‚¬ìš©ìê°€ ì…ë ¥í•œ í•„ë“œë§Œ ì„¤ëª…í•˜ë„ë¡ ìš”ì²­
            fields_explanation = []
            if "ì£¼ìš”ì—…ë¬´" in provided_fields:
                fields_explanation.append("ì£¼ìš”ì—…ë¬´")
            if "ìê²©ìš”ê±´ë°ìš°ëŒ€ì‚¬í•­" in provided_fields:
                fields_explanation.append("ìê²©ìš”ê±´")
                fields_explanation.append("ìš°ëŒ€ì‚¬í•­")
            if "í˜œíƒë°ë³µì§€" in provided_fields:
                fields_explanation.append("í˜œíƒë°ë³µì§€")
            fields_text = ", ".join(fields_explanation)
        
            prompt += (
                "ìœ„ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ, ê° ì¶”ì²œ ê³µê³ ì— ëŒ€í•´ ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì†Œí”„íŠ¸ í•„í„° í•­ëª© ì¤‘ "
                f"[{fields_text}]ì— í•´ë‹¹í•˜ëŠ” ë¶€ë¶„ì´ ê³µê³  ë‚´ìš©ì—ì„œ ì–´ë–»ê²Œ ë‚˜íƒ€ë‚˜ëŠ”ì§€ ì•„ë˜ í˜•ì‹ìœ¼ë¡œ ì„¤ëª…í•´ ì£¼ì„¸ìš”.\n\n"
                "í˜•ì‹ (ë§ˆí¬ë‹¤ìš´ í˜•ì‹):\n"
                "ğŸ”·**Top 1: [ê³µê³ ì œëª©]**\n\n"
            )
            if "ì£¼ìš”ì—…ë¬´" in provided_fields:
                prompt += " â–ªï¸ **ì£¼ìš”ì—…ë¬´:** <ì„¤ëª…>\n\n"
            if "ìê²©ìš”ê±´ë°ìš°ëŒ€ì‚¬í•­" in provided_fields:
                prompt += " â–ªï¸ **ìê²©ìš”ê±´:** <ì„¤ëª…>\n\n"
                prompt += " â–ªï¸ **ìš°ëŒ€ì‚¬í•­:** <ì„¤ëª…>\n\n"
            if "í˜œíƒë°ë³µì§€" in provided_fields:
                prompt += " â–ªï¸ **í˜œíƒë°ë³µì§€:** <ì„¤ëª…>\n\n"
        
            # â–¼â–¼â–¼ ë³€ê²½/ì¶”ê°€ëœ ë¶€ë¶„ â–¼â–¼â–¼
            prompt += (
                "ë‹¨, ì‚¬ìš©ìê°€ ì…ë ¥í•˜ì§€ ì•Šì€ í•­ëª©ì€ ì•„ì˜ˆ ì„¤ëª…ì—ì„œ ìƒëµí•´ ì£¼ì„¸ìš”. "
                "ë˜í•œ, í•´ë‹¹ í•­ëª©ì´ ê³µê³  ë‚´ìš©ì—ì„œ ëª…í™•í•˜ê²Œ ë‚˜íƒ€ë‚˜ì§€ ì•ŠëŠ” ê²½ìš°, 'í•´ë‹¹ í•­ëª©ê³¼ ê´€ë ¨ëœ ë‚´ìš©ì´ ëª…í™•í•˜ê²Œ ë‚˜íƒ€ë‚˜ì§€ ì•Šì•„ìš”'ë¼ê³  ê°„ë‹¨í•˜ê²Œ ì–¸ê¸‰í•´ ì£¼ì„¸ìš”.\n\n"
                "**ì¤‘ìš”**: Top 1ë¶€í„° Top 5ê¹Œì§€ë¥¼ ì ˆëŒ€ë¡œ ìƒëµí•˜ì§€ ë§ê³  ì „ë¶€ ë³„ë„ë¡œ ì„¤ëª…í•´ ì£¼ì„¸ìš”. "
                "'ì´í•˜ ìƒëµ', '...' ë“±ì˜ ìš”ì•½ í‘œí˜„ ì—†ì´, ê° ê³µê³ ë¥¼ ëª¨ë‘ êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±í•´ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤."
            )
            # â–²â–²â–² ë³€ê²½/ì¶”ê°€ëœ ë¶€ë¶„ â–²â–²â–²
        
            try:
                response = client.chat.completions.create(
                    model="gpt-4o",
                    messages=[
                        {
                            "role": "system",
                            "content": (
                                "You are an assistant who explains job recommendation rationale based on user input "
                                "and job posting data in markdown format. Do not fabricate explanations if the user's input "
                                "is not clearly supported by the job posting content."
                            )
                        },
                        {"role": "user", "content": prompt},
                    ],
                    temperature=0.5
                )
                explanation = response.choices[0].message.content
            except Exception as e:
                explanation = f"ì¶”ì²œ ì‚¬ìœ ë¥¼ ìƒì„±í•˜ëŠ” ë° ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš”: {e}"
        
            return explanation

        
        ######################################################
        # ì¶”ê°€: ë¡œë”© ë©”ì‹œì§€ì™€ í•¨ê»˜ ì¶”ì²œ ì‚¬ìœ  ìƒì„± ë° ì¶œë ¥
        ######################################################
        loading_msg = st.empty()
        loading_msg.markdown("#### â³ê³µê³  ì¶”ì²œ ì´ìœ ë¥¼ ì•Œë ¤ë“œë¦´ê²Œìš”. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”â˜ºï¸âŒ›")

        explanation = generate_recommendation_rationale(user_input_json, top_df)

        loading_msg.empty()

        st.markdown("### ê³µê³  ì¶”ì²œ ì´ìœ ")
        st.write(explanation)