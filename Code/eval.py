import openai
import google.generativeai as genai
import pandas as pd
import json
from tqdm import tqdm
import time
import re

############################
# API ì„¤ì •
############################
# Gemini API ì„¤ì •
GOOGLE_API_KEY = "ê°œì¸_API_key" 
genai.configure(api_key=GOOGLE_API_KEY)

############################
# 0) ì „ì—­ DataFrame ì¤€ë¹„
############################
coverage_result_columns = ["model", "num", "rank", "ì£¼ìš”ì—…ë¬´", "ìê²©ìš”ê±´ë°ìš°ëŒ€ì‚¬í•­", "í˜œíƒë°ë³µì§€"]
coverage_df = pd.DataFrame(columns=coverage_result_columns)

############################
# 1) Gemini API ì´ìš©í•œ í‚¤ì›Œë“œ ì¶”ì¶œ í•¨ìˆ˜
## ì…ë ¥: ./user_input.xlsx
## ì¶œë ¥: ./user_input_keyword.json
############################
def extract_keywords(text: str) -> list:
    """ GPT ê¸°ë°˜ í‚¤ì›Œë“œ ì¶”ì¶œ í•¨ìˆ˜ """
    if not text.strip():
        return []

    system_prompt = (
        """
        ## Role
        You are an AI assistant responsible for understanding a userâ€™s recruitment or job-related requirements. 
        You must correct any spelling or grammatical errors in the userâ€™s text, then extract and return the essential keywords in JSON format.

        ## Common Conditions
        1) Keywords must be concise, between 1 and 4 words in length.
        2) If there are spelling or grammatical mistakes, you should correct them naturally before extracting keywords.
        3) Avoid over-segmentation: if multiple words share the same core meaning, combine them into one keyword.
        4) The output must be in JSON format: {"keywords": ["keyword1", "keyword2"]}
        5) Provide no additional explanatory text or any output other than the JSON structure.
        6) If a term is originally from English but spelled in Korean (e.g., â€œë§ˆìºíŒ…â€), identify and correct the likely English origin (e.g., â€œMarketingâ€) and use that corrected form when generating the final keyword.
        7) Extract keywords in the **same language as the input**:  
           - **Korean input â†’ Korean keywords**  
           - **English input â†’ English keywords** 
        8) For conjunctions like â€œë°,â€ â€œand,â€ or â€œor,â€ follow these rules:  
           - **Same Action/Concept:** Treat as one keyword.  
                 - Example: "ë¨¸ì‹ ëŸ¬ë‹ ë° ë”¥ëŸ¬ë‹ ëª¨ë¸ êµ¬ì¶•" â†’ ["ë¨¸ì‹ ëŸ¬ë‹ ë° ë”¥ëŸ¬ë‹ ëª¨ë¸ êµ¬ì¶•"]  
           - **Distinct Actions/Concepts:** Separate into individual keywords.  
                 - Example: "Python ë° R í”„ë¡œê·¸ë˜ë°" â†’ ["Python í”„ë¡œê·¸ë˜ë°", "R í”„ë¡œê·¸ë˜ë°"]  
           - **Unclear Context:** Default to one keyword.
                 - Example: "LLM ëª¨ë¸ íŒŒì¸íŠœë‹ ë° êµ¬í˜„" â†’ ["LLM ëª¨ë¸ íŒŒì¸íŠœë‹ ë° êµ¬í˜„"]  

        ## Category-Specific Conditions

        ### Job Title
        - If the text refers to a job title, consider the entire phrase (even if it consists of multiple words) as one single keyword.
        - Example1: â€œData Analytics Managerâ€ â†’ single keyword
        - Example2: "ì „ëµ ì»¨ì†”í„°íŠ¸" â†’ "ì „ëµ ì»¨ì„¤í„´íŠ¸" (after correcting spelling or grammar)

        ### Main Duties
        - If the text describes key tasks or responsibilities, extract them as separate keywords in 1â€“4 words.
        - Example: â€œanalyzing business metrics,â€ â€œcreating data dashboardsâ€

        ### Qualifications / Preferred Skills
        - If the text discusses qualifications or preferred skills, extract them in concise 1â€“4 word phrases.
        - Example: â€œPython proficiency,â€ â€œStatistical modeling,â€ â€œMachine learning experienceâ€

        ### Benefits / Welfare
        - If multiple benefit or welfare items appear in a single sentence, separate them into individual keywords.
        - Example: â€œFlexible working hours,â€ â€œHealth insurance,â€ â€œOnsite gym accessâ€
        """
    )

    user_prompt = (
        f" Please extract concise keywords (1â€“4 words) from the text below, following the system rules. \n"
        f"Text: {text} \n\n"
        f"Return the result in JSON with the key 'keywords' and no additional text."
    )

    start_time = time.time()
    print("ğŸš€ Gemini API í˜¸ì¶œ ì¤‘... (í‚¤ì›Œë“œ ì¶”ì¶œ)")

    try:
        # Gemini ëª¨ë¸ ì„¤ì • (ì˜ˆ: gemini-2.0-flash)
        model = genai.GenerativeModel('gemini-2.0-flash')
        temperature = 0  

        prompt_text = f"{system_prompt}\n\n{user_prompt}"
        response = model.generate_content(
            prompt_text,
            generation_config=genai.GenerationConfig(temperature=temperature)
        )

        response_text = response.text.strip()

        # JSON ì‘ë‹µ íŒŒì‹±
        if response_text.startswith("[") or response_text.startswith("{"):
            try:
                parsed = json.loads(response_text)
                if "keywords" in parsed and isinstance(parsed["keywords"], list):
                    return parsed["keywords"]
                else:
                    return []
            except json.JSONDecodeError:
                pass

        # ì½”ë“œ ë¸”ë¡ ì œê±°
        response_text = response_text.replace("```json", "").replace("```", "")

        end_time = time.time()
        print(f"âœ… ì™„ë£Œ! â±ï¸ ì‹¤í–‰ ì‹œê°„: {round(end_time - start_time, 2)}ì´ˆ")
        time.sleep(5)
        return response_text.strip()

    except Exception as e:
        print(f"âŒ í‚¤ì›Œë“œ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return []

############################
# 2) Gemini API ì´ìš©í•œ ì»¤ë²„ë¦¬ì§€ & ë””ë²„ê·¸ ê³„ì‚°
############################
def evaluate_and_debug_with_gemini(user_input_json, top_df_BGE, top_df_Jina, api_call_count):
    """
    1) LLM í˜¸ì¶œ â†’ Coverage í…œí”Œë¦¿(ê·œê²©) + Debug Info(í‚¤ì›Œë“œë³„ MATCH/NO MATCH + (Matched/Total))
    2) Debug Infoì—ì„œ (# Matched / # Total) = coverage ë¹„ìœ¨ ê³„ì‚°
    3) coverage_results_debug.csvì— ì €ì¥
    """
    global coverage_df

    iteration = user_input_json.get("num", 1) # ë””ë²„ê·¸ ë¸”ë¡ ë¶€ë¶„ì€ ê·¸ëƒ¥ í…ìŠ¤íŠ¸ë¡œ íŒŒì‹±í•´ì„œ print() (ë˜ëŠ” í•„ìš”ì‹œ ì €ì¥)
    
    # ë§Œì•½ 15íšŒë§ˆë‹¤ 60ì´ˆ ì¿¨ë‹¤ìš´ì´ í•„ìš”í•˜ë‹¤ë©´:
    if api_call_count > 0 and api_call_count % 15 == 0:
        print("â³ ìœ ì‚¬ë„ ì ìˆ˜ ê³„ì‚° ì¤‘ 60ì´ˆ ëŒ€ê¸° ì¤‘...")
        time.sleep(60)

    # --------------------------
    # (1) System Prompt
    # --------------------------
    # "No additional text"ì´ë¼ëŠ” ë¬¸êµ¬ê°€ ìˆì§€ë§Œ,
    #   - "ì»¤ë²„ë¦¬ì§€ í…œí”Œë¦¿" ë’¤ì—ëŠ” "DEBUG_INFO:" ë¸”ë¡ì„ í—ˆìš©í•œë‹¤.
    #   - (ì»¤ë²„ë¦¬ì§€ í…œí”Œë¦¿ + DEBUG_INFO ë¸”ë¡)ì„ ëª¨ë‘ ì¶œë ¥í•˜ë„ë¡ ì§€ì‹œ.
    system_prompt = '''
You are a professional job matching evaluator.

# CRITICAL CALCULATION INSTRUCTIONS - HIGHEST PRIORITY
For each category (job_task, job_skills, job_benefits):
1. Calculate coverage ratio PRECISELY as: (Number of MATCH items) Ã· (Total number of items in category)
2. Example:
   - If there are 3 total job_task items and 2 are marked as MATCH(1.0), then:
   - job_task ratio = 2/3 = 0.6666... (NOT 1.0)
3. Never round up to 1.0 - use the exact division result
4. Always use all items in the denominator, whether they match or not

CALCULATION ALGORITHM:
def calculate_coverage(category_items):
total_items = len(category_items)  # All items in category
matched_items = sum(1 for item in category_items if item['status'] == 'MATCH')
ratio = matched_items / total_items  # Must perform actual division
return ratio

# IMPORTANT:
We want you to produce TWO parts in your final answer:

1) The Coverage Template Block (EXACT format, no extra text):
   num_{iteration} = {
     bge_{iteration}_rank_1 = {ì£¼ìš”ì—…ë¬´ = X, ìê²©ìš”ê±´ë°ìš°ëŒ€ì‚¬í•­ = Y, í˜œíƒë°ë³µì§€ = Z},
     bge_{iteration}_rank_2 = {...},
     bge_{iteration}_rank_3 = {...},
     bge_{iteration}_rank_4 = {...},
     bge_{iteration}_rank_5 = {...},
     jina_{iteration}_rank_1 = {...},
     jina_{iteration}_rank_2 = {...},
     jina_{iteration}_rank_3 = {...},
     jina_{iteration}_rank_4 = {...},
     jina_{iteration}_rank_5 = {...}
   }

   Where X, Y, Z are coverage ratios (floats from 0.0 to 1.0). No extra lines or text.

2) The Debug Info Block (after the coverage block). 
   - Begin with the line "DEBUG_INFO:" on its own, then list debug lines. Example:
     [Debug for BGE rank=1]
     - job_task('í‚¤ì›Œë“œ'): MATCH(1.0) â†’ "ì´ìœ "
     - job_skills('í‚¤ì›Œë“œ'): NO MATCH(0.0) â†’ "ì´ìœ "
     ...
     - **job_task = (X / {ì£¼ìš”ì—…ë¬´ í‚¤ì›Œë“œ ê°œìˆ˜})** 
     - **job_skills = (Y / {ìê²©ìš”ê±´ë°ìš°ëŒ€ì‚¬í•­ í‚¤ì›Œë“œ ê°œìˆ˜})** 
     - **job_benefits = (Z / {í˜œíƒë°ë³µì§€ í‚¤ì›Œë“œ ê°œìˆ˜})**
    - Keep it concise, 1-2 lines per keyword describing how you decided MATCH or NO MATCH.

# Coverage Evaluation Criteria
1) Take the user's query (in JSON), which contains keywords for certain fields and the "num" field for the iteration number.
2) For each job post (Top 5 from BGE and Top 5 from Jina), focus only on these 3 fields:
   - "ì£¼ìš”ì—…ë¬´"
   - "ìê²©ìš”ê±´ë°ìš°ëŒ€ì‚¬í•­"
   - "í˜œíƒë°ë³µì§€"

3) For each field, compute coverage ratio as follows:
   Coverage Ratio = (# Matched Keywords) / (# Total Keywords in user's query for that field)
   - The numerator is the COUNT of keywords marked as MATCH (1.0)
   - The denominator is the TOTAL COUNT of keywords in the user's query for that field
   - Each keyword contributes exactly 0 or 1 to the numerator (no partial counting)

4) **Enhanced Semantic Similarity Rule for Matching Keywords**
   - Allow for **conceptually related**, **contextually similar**, or **domain-specific** keyword matches.
   - Prioritize **semantic similarity** over exact matching.
   - **Partial matches are NOT allowed.** However, if two terms share over 70% semantic similarity or serve the same purpose in context, treat them as MATCH.
     - Example: "ì‚¬ì—… ê°œë°œ" â†” "ë¹„ì¦ˆë‹ˆìŠ¤ ì„±ì¥ ì „ëµ" (âœ… MATCH)
     - Example: "íŒŒíŠ¸ë„ˆì‹­ ê°œë°œ" â†” "í˜‘ë ¥ ê¸°íšŒ í™•ëŒ€" (âœ… MATCH)

5) **Flexible Matching Guidelines for ALL COLUMNS**
   - Recognize **broader concepts**, **synonyms**, and **job-specific terminology** as matches.
   - Allow flexible interpretation for all 3 categories: **ì£¼ìš”ì—…ë¬´**, **ìê²©ìš”ê±´ë°ìš°ëŒ€ì‚¬í•­**, **í˜œíƒë°ë³µì§€**.
   - **Partial matches are NOT allowed.**
   - Match keywords that are **broader in concept** but still relevant.  
     - Example: "ê²½ì˜ ì»¨ì„¤í„´íŠ¸" â†” "ì „ëµ ì»¨ì„¤í„´íŠ¸" (âœ… Match)  
     - Example: "ê¸°ì—… ê²½ì˜ ë¶„ì„" â†” "ë¹„ì¦ˆë‹ˆìŠ¤ ì„±ê³¼ ë¶„ì„" (âœ… Match)  
     - Example: "ì¬ë¬´ ë¶„ì„" â†” "ì¬ë¬´ ë¦¬í¬íŠ¸ ì‘ì„±" (âœ… Match)  
   - Consider **role-related synonyms** or job-specific terminology.  
     - Example: "ë¸Œëœë“œ ì „ëµ ê¸°íš" â†” "ë¸Œëœë“œ ë§ˆì¼€íŒ… ê¸°íš" (âœ… Match)  
     - Example: "ê´‘ê³  ìº í˜ì¸ ìš´ì˜" â†” "ë§ˆì¼€íŒ… ì´ë²¤íŠ¸ ê¸°íš" (âœ… Match)  
   - Match **supportive skills or experience** with relevant technical keywords.  
     - Example: "ë°ì´í„° ë¶„ì„ ê²½í—˜" â†” "SQL, íŒŒì´ì¬ ê¸°ë°˜ ë°ì´í„° ë¶„ì„" (âœ… Match)  
     - Example: "ì»¨ì„¤íŒ… í”„ë¡œì íŠ¸ ê²½í—˜" â†” "í”„ë¡œì íŠ¸ ë§¤ë‹ˆì§€ë¨¼íŠ¸" (âœ… Match)  
   - Allow for flexible interpretation in matching ë³µì§€ í˜œíƒ.  
     - Example:
       - "ììœ¨ ì¶œí‡´ê·¼ ì œë„" â†” "ìœ ì—° ê·¼ë¬´" (âœ… Match)
       - "í—¬ìŠ¤ì¥ ì§€ì›" â†” "í—¬ìŠ¤ ë©¤ë²„ì‹­ ì œê³µ" (âœ… Match)
       - "ì‹ëŒ€ ì§€ì›" â†” "ì ì‹¬ ì œê³µ" (âœ… Match)
       - "ì—°ì°¨ ì œë„" â†” "ì—°ì°¨ ìœ ê¸‰ íœ´ê°€" (âœ… Match)

6) Matching Rules for Accuracy:
   - Count each keyword only ONCE per field (no duplicates).  
   - Prevent inflated scores by limiting **redundant matches** to a single count.
   - Identify synonyms, semantically equivalent expressions, or translated terms as matches.  
   - Avoid matching unrelated terms or keywords that distort the intended meaning.
     - "ê²½ì˜" â†” "ê¸°ì—… ê²½ì˜ ë¶„ì„" (âŒ No Match)
     - "ë°ì´í„° ì‚­ì œ" â†” "ë°ì´í„° ë¶„ì„" (âŒ No Match)

7) **Keyword Expansion for Comprehensive Matching**
   - Broaden keyword matching to include relevant concepts and skills.
     - Example: "ë¨¸ì‹ ëŸ¬ë‹" â†” "AI ëª¨ë¸ êµ¬ì¶•" (âœ… Match)  
     - Example: "ë¸Œëœë“œ ì „ëµ" â†” "ë¸Œëœë“œ ê´€ë¦¬" (âœ… Match)  
   - Consider **industry-specific language** as valid matches.
     - Example: "SQL" â†” "ë°ì´í„°ë² ì´ìŠ¤" (âœ… Match)  
     - Example: "ì „ëµ ê¸°íš" â†” "ì „ëµì  ì˜ì‚¬ê²°ì •" (âœ… Match)  

8) For ìê²©ìš”ê±´ë°ìš°ëŒ€ì‚¬í•­:  
   **Use the newly created column 'ìê²©ìš”ê±´ë°ìš°ëŒ€ì‚¬í•­' in the job post to determine matching.**  
   In other words, if the user has N total keywords under "ìê²©ìš”ê±´ë°ìš°ëŒ€ì‚¬í•­," then count how many of these keywords appear in the combined 'ìê²©ìš”ê±´ë°ìš°ëŒ€ì‚¬í•­' column of the job post.  
   Summing these matches yields the coverage numerator; dividing by N yields the coverage ratio for "ìê²©ìš”ê±´ë°ìš°ëŒ€ì‚¬í•­."  
   (Note that each keyword is counted only once per field, even if it appears multiple times in the text.)

9) For each post (rank=1..5 in BGE and Jina), calculate the coverage ratio for each of these 3 fields, then fill in the values X, Y, Z in the template accordingly.

10) **Coverage Ratio Calculation - CRITICAL**:
   - The denominator MUST always equal the user's total keywords for that field.
   - The numerator is the COUNT of items marked as MATCH(1.0).
   - Format example: job_task = (2.0 / 3)
     - Use numbers only, no words like "# Matched Keywords."
   - The final coverage ratio in the Coverage Template must exactly match these counts.
   - IMPORTANT: A ratio of 2/3 should be calculated as 0.6666... not as 1.0

# NO Extra Explanation beyond these two blocks
1) The coverage block
2) "DEBUG_INFO:" block

Any other text is not allowed.
'''

    # --------------------------
    # (2) User Prompt
    # --------------------------
    iteration = user_input_json.get("num", 1)
    
    user_prompt = f"""
    User's query (JSON): {user_input_json}
    The iteration is #{iteration}.
    
        
    Below are the top 5 job posts from BGE and top 5 job posts from Jina (all fields). 
    Calculate coverage ratio only for "ì£¼ìš”ì—…ë¬´", "ìê²©ìš”ê±´ë°ìš°ëŒ€ì‚¬í•­", "í˜œíƒë°ë³µì§€".
    Then produce your final answer strictly in the required template.
    """

    # ì‹œí–‰ë²ˆí˜¸ì— ë§ê²Œ BGE/JINA í•„í„°
    filtered_bge = top_df_BGE[top_df_BGE['ì‹œí–‰'] == iteration].sort_values(by='rank')
    filtered_jina = top_df_Jina[top_df_Jina['ì‹œí–‰'] == iteration].sort_values(by='rank')

    # --------------------------
    # (2) User Prompt
    # --------------------------
    user_prompt = f"User's query (JSON): {user_input_json}\nThe iteration is #{iteration}.\n\n"

    # ì‹œí–‰ë²ˆí˜¸ì— ë§ê²Œ BGE/JINA í•„í„°
    filtered_bge = top_df_BGE[top_df_BGE['ì‹œí–‰'] == iteration].sort_values(by='rank')
    filtered_jina = top_df_Jina[top_df_Jina['ì‹œí–‰'] == iteration].sort_values(by='rank')

    # BGE posts
    doc_bge_str = "BGE posts:\n"
    for idx, row in filtered_bge.iterrows():
        doc_bge_str += (
             f"[Rank={row.get('rank','')}] "
             f"ì£¼ìš”ì—…ë¬´: {row.get('ì£¼ìš”ì—…ë¬´','')}\n"
             f"ìê²©ìš”ê±´ë°ìš°ëŒ€ì‚¬í•­: {row.get('ìê²©ìš”ê±´ë°ìš°ëŒ€ì‚¬í•­','')}\n"
             f"í˜œíƒë°ë³µì§€: {row.get('í˜œíƒë°ë³µì§€','')}\n\n"
        )

    # Jina posts
    doc_jina_str = "Jina posts:\n"
    for idx, row in filtered_jina.iterrows():
        doc_jina_str += (
             f"[Rank={row['rank']}] "
             f"ì£¼ìš”ì—…ë¬´: {row.get('ì£¼ìš”ì—…ë¬´','')}\n"
             f"ìê²©ìš”ê±´ë°ìš°ëŒ€ì‚¬í•­: {row.get('ìê²©ìš”ê±´ë°ìš°ëŒ€ì‚¬í•­','')}\n"
             f"í˜œíƒë°ë³µì§€: {row.get('í˜œíƒë°ë³µì§€','')}\n\n"
        )
    
    final_user_prompt = f"{user_prompt}\n\n{doc_bge_str}\n{doc_jina_str}\n"

    # --------------------------
    # (3) LLM í˜¸ì¶œ
    # --------------------------
    print("ğŸš€ Gemini API í˜¸ì¶œ (Coverage + Debug) ...")
    start_time = time.time()
    
    # Gemini í˜¸ì¶œ
    try:
        model = genai.GenerativeModel('gemini-2.0-flash')
        prompt_text = f"{system_prompt}\n\n{final_user_prompt}"
        response = model.generate_content(
            prompt_text, generation_config=genai.GenerationConfig(temperature=0.0)
        )
        response_text = response.text.strip()

        # Coverage í…œí”Œë¦¿ + Debug Info ë¶„í• 
        coverage_part, debug_part = split_coverage_and_debug(response_text)

        # Debug Infoì—ì„œ Coverage ë¹„ìœ¨ ì¶”ì¶œ
        debug_info = format_debug_info_with_ratios(debug_part, user_input_json)

        # Coverage CSV ì €ì¥
        save_coverage_from_debug(debug_info, iteration)

        # Debug íŒŒì¼ë¡œ ì €ì¥
        debug_filename = f"debug_log_{iteration}.json"
        with open(debug_filename, 'w', encoding='utf-8') as f:
            json.dump({"debug_info": debug_info}, f, ensure_ascii=False, indent=2)
        print(f"âœ… ë””ë²„ê·¸ ë¡œê·¸ ì €ì¥ ì™„ë£Œ: {debug_filename}")

        end_time = time.time()
        print(f"âœ… ì™„ë£Œ! â±ï¸ ì‹¤í–‰ ì‹œê°„: {round(end_time - start_time, 2)}ì´ˆ")

        response_text = coverage_part + "\nDEBUG_INFO:\n" + debug_part
        return response_text

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        if "429" in str(e):
            print("â³ 429 ì˜¤ë¥˜ ë°œìƒ, 60ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„...")
            time.sleep(60)  # 429 ì˜¤ë¥˜ ë°œìƒ ì‹œ 1ë¶„ ëŒ€ê¸° í›„ ì¬ì‹œë„
            return evaluate_and_debug_with_gemini(user_input_json, top_df_BGE, top_df_Jina, api_call_count)  
        return "âŒ ìµœì¢… ì˜¤ë¥˜: ë°ì´í„° í˜¸ì¶œ ì‹¤íŒ¨"

############################
# 3) Coverageì™€ Debug ë¶„ë¦¬ í•¨ìˆ˜
############################
def split_coverage_and_debug(full_text: str):
    """
    LLM ì‘ë‹µì—ì„œ:
    1) Coverage í…œí”Œë¦¿
    2) Debug Info
    ë¥¼ ë¶„ë¦¬í•´ ë°˜í™˜
    """
    if "DEBUG_INFO:" in full_text:
        parts = full_text.split("DEBUG_INFO:", 1)
        coverage_part = parts[0].strip()
        debug_part = parts[1].strip()
    else:
        coverage_part = full_text
        debug_part = ""

    return coverage_part, debug_part

#############################
# 4-1) Debug íŒŒì‹± í•¨ìˆ˜
###############################
def format_debug_info_with_ratios(debug_block: str, user_input_json: dict) -> dict:
    """
    1) Debug Blockì—ì„œ job_task = (X / Y) ë“± ë¹„ìœ¨ì„ íŒŒì‹±í•˜ì—¬ ì •í™•íˆ ë°˜ì˜
    2) MATCH / NO MATCH ì •ë³´ë¥¼ í•¨ê»˜ ì €ì¥
    """
    debug_info = {}
    current_rank = None
    
    # ì´ í‚¤ì›Œë“œ ê°œìˆ˜
    total_task_keywords = len(user_input_json.get('ì£¼ìš”ì—…ë¬´', []))
    total_skills_keywords = len(user_input_json.get('ìê²©ìš”ê±´ë°ìš°ëŒ€ì‚¬í•­', []))
    total_benefits_keywords = len(user_input_json.get('í˜œíƒë°ë³µì§€', []))
    
    lines = debug_block.strip().split("\n")
    
    i = 0
    while i < len(lines):
        line = lines[i].strip()
        
        # ìƒˆë¡œìš´ ë­í¬ ì‹œì‘
        if "[Debug for" in line:
            if current_rank:
                # ì´ì „ ë­í¬ì— ëŒ€í•œ ì •ë³´ë¥¼ ì €ì¥
                debug_info[current_rank] = {
                    "job_task": task_ratio,
                    "job_skills": skills_ratio,
                    "job_benefits": benefits_ratio,
                    "match_details": match_details
                }
            
            # í˜„ì¬ ë­í¬ ì •ë³´ ì´ˆê¸°í™”
            current_rank = line.strip("[]")
            match_details = []
            matched_task = matched_skills = matched_benefits = 0
            task_ratio = skills_ratio = benefits_ratio = 0.0
            
            # í˜„ì¬ ë­í¬ì˜ ë§¤ì¹­ ì •ë³´ ìˆ˜ì§‘
            i += 1
            collecting_details = True
            
            while i < len(lines) and collecting_details:
                detail_line = lines[i].strip()
                
                # ë‹¤ìŒ ë­í¬ê°€ ì‹œì‘ë˜ë©´ ì¤‘ë‹¨
                if "[Debug for" in detail_line:
                    i -= 1  # ë‹¤ìŒ ë°˜ë³µì—ì„œ ì´ ë¼ì¸ì„ ë‹¤ì‹œ ì²˜ë¦¬í•˜ë„ë¡
                    collecting_details = False
                    continue
                
                # ë¹„ì–´ìˆëŠ” ë¼ì¸ ê±´ë„ˆë›°ê¸°
                if not detail_line:
                    i += 1
                    continue
                
                # ë§¤ì¹­ ìƒì„¸ ì •ë³´ ì €ì¥
                if "job_task(" in detail_line or "job_skills(" in detail_line or "job_benefits(" in detail_line:
                    match_details.append(detail_line)
                    if "MATCH(1.0)" in detail_line:
                        if "job_task(" in detail_line:
                            matched_task += 1
                        elif "job_skills(" in detail_line:
                            matched_skills += 1
                        elif "job_benefits(" in detail_line:
                            matched_benefits += 1
                
                # ë¹„ìœ¨ ì •ë³´ íŒŒì‹±
                if "job_task =" in detail_line:
                    match = re.search(r'\((\d+)(?:\.\d+)?\s*/\s*(\d+)\)', detail_line)
                    if match:
                        numerator = int(match.group(1))
                        denominator = int(match.group(2))
                        if denominator > 0:
                            task_ratio = numerator / denominator
                        else:
                            task_ratio = 0.0
                
                elif "job_skills =" in detail_line:
                    match = re.search(r'\((\d+)(?:\.\d+)?\s*/\s*(\d+)\)', detail_line)
                    if match:
                        numerator = int(match.group(1))
                        denominator = int(match.group(2))
                        if denominator > 0:
                            skills_ratio = numerator / denominator
                        else:
                            skills_ratio = 0.0
                
                elif "job_benefits =" in detail_line:
                    match = re.search(r'\((\d+)(?:\.\d+)?\s*/\s*(\d+)\)', detail_line)
                    if match:
                        numerator = int(match.group(1))
                        denominator = int(match.group(2))
                        if denominator > 0:
                            benefits_ratio = numerator / denominator
                        else:
                            benefits_ratio = 0.0
                
                i += 1
            
            # ë£¨í”„ë¥¼ ë‚˜ì™”ì„ ë•Œ ië¥¼ ì¦ê°€ì‹œí‚¤ì§€ ì•ŠìŒ (ì´ë¯¸ ìœ„ì˜ ë£¨í”„ì—ì„œ ì¦ê°€ë¨)
            continue
        
        i += 1
    
    # ë§ˆì§€ë§‰ ë­í¬ ì €ì¥
    if current_rank:
        debug_info[current_rank] = {
            "job_task": task_ratio,
            "job_skills": skills_ratio,
            "job_benefits": benefits_ratio,
            "match_details": match_details
        }
    
    return debug_info

############################
# 4-2) Coverage ì €ì¥ í•¨ìˆ˜
############################
def save_coverage_from_debug(debug_info: dict, iteration_num: int):
    """
    Debug Infoë¥¼ ê¸°ë°˜ìœ¼ë¡œ coverage_results_debug.csvì— ì €ì¥
    """
    global coverage_df

    row_list = []
    for rank_key, coverage_dict in debug_info.items():
        if "BGE" in rank_key.upper():
            model_name = "bge"
        else:
            model_name = "jina"

        # rank= ë’¤ì˜ ìˆ«ì ì¶”ì¶œ
        rank_match = re.search(r'rank=(\d+)', rank_key)
        rank_str = rank_match.group(1) if rank_match else "1"

        row_dict = {
            "model": model_name,
            "num": str(iteration_num),
            "rank": rank_str,
            "ì£¼ìš”ì—…ë¬´": coverage_dict["job_task"],
            "ìê²©ìš”ê±´ë°ìš°ëŒ€ì‚¬í•­": coverage_dict["job_skills"],
            "í˜œíƒë°ë³µì§€": coverage_dict["job_benefits"]
        }
        row_list.append(row_dict)

    if row_list:
        row_df = pd.DataFrame(row_list)
        coverage_df = pd.concat([coverage_df, row_df], ignore_index=True)
        coverage_df.to_csv("coverage_results.csv", index=False, encoding='utf-8-sig')
        print(f"âœ… coverage_results_debug.csv íŒŒì¼ì— {len(row_list)}ê°œ í–‰ ì €ì¥ ì™„ë£Œ")

############################
# 5) ì‚¬ìš©ìì˜ ì¤‘ìš”ë„ë¥¼ ê°€ì¤‘ì¹˜ ë°˜í™˜ í›„, ìµœì¢… ì ìˆ˜ ê³„ì‚° í•¨ìˆ˜
############################
def calculate_finscore(coverage_df, user_data):
    """
    ì¤‘ìš”ë„ ê³ ë ¤í•œ ìµœì¢… ì ìˆ˜ ê³„ì‚° í•¨ìˆ˜
    """
    weights_dict = {
        item['num']: {
            'job_skills_weight': item['job_skills']['weight'],
            'job_task_weight': item['job_task']['weight'],
            'job_benefits_weight': item['job_benefits']['weight']
        }
        for item in user_data
    }

    def apply_weights(row):
        weights = weights_dict.get(row['num'], {
            'job_skills_weight': 0,
            'job_task_weight': 0,
            'job_benefits_weight': 0
        })
        row['ì£¼ìš”ì—…ë¬´'] = row['ì£¼ìš”ì—…ë¬´'] * weights['job_task_weight']
        row['ìê²©ìš”ê±´ë°ìš°ëŒ€ì‚¬í•­'] = row['ìê²©ìš”ê±´ë°ìš°ëŒ€ì‚¬í•­'] * weights['job_skills_weight']
        row['í˜œíƒë°ë³µì§€'] = row['í˜œíƒë°ë³µì§€'] * weights['job_benefits_weight']
        row['ì¢…í•©ì ìˆ˜'] = row['ì£¼ìš”ì—…ë¬´'] + row['ìê²©ìš”ê±´ë°ìš°ëŒ€ì‚¬í•­'] + row['í˜œíƒë°ë³µì§€']
        return row

    return coverage_df.apply(apply_weights, axis=1)


############################
# 5) main ì‹¤í–‰
############################
if __name__ == "__main__":
    # =============================
    # ì‚¬ìš©ì ì…ë ¥ -> í‚¤ì›Œë“œ ì¶”ì¶œ í›„ JSON ìƒì„±
    # =============================
    file_user_input = './user_input.xlsx'
    user_input = pd.read_excel(file_user_input)

    ####ê°€ì¤‘ì¹˜ ê³„ì‚°í•˜ëŠ” ì½”ë“œ ì¶”ê°€#######
    columns = ['ì£¼ìš”ì—…ë¬´ì¤‘ìš”ë„', 'ìê²©ìš”ê±´ë°ìš°ëŒ€ì‚¬í•­ì¤‘ìš”ë„', 'í˜œíƒë°ë³µì§€ì¤‘ìš”ë„']
    row_sums = user_input[columns].sum(axis=1)
    user_input[columns] = user_input[columns].div(row_sums, axis=0)
    user_input.to_excel('./user_input_weighted.xlsx', index=False)
    ####ê°€ì¤‘ì¹˜ ê³„ì‚°í•˜ëŠ” ì½”ë“œ ì¶”ê°€#######

    # 'ì‹œí–‰' ì—´ ê¸°ì¤€ìœ¼ë¡œ ë°ì´í„° í•„í„°ë§
    user_input_filtered = user_input[user_input['ì‹œí–‰'].notna()]

    # í‚¤ì›Œë“œ ì¶”ì¶œ JSON ìƒì„±
    user_input_keyword = []

    # âœ… Gemini í˜¸ì¶œ íšŸìˆ˜ ì¹´ìš´íŠ¸ ì¶”ê°€
    api_call_count = 0  

    for idx, row in user_input_filtered.iterrows():
        
        # âœ… 15íšŒë§ˆë‹¤ 60ì´ˆ ëŒ€ê¸°
        if api_call_count > 0 and api_call_count % 15 == 0:
            print("â³ í‚¤ì›Œë“œ ì¶”ì¶œ ì¤‘ 60ì´ˆ ëŒ€ê¸° ì¤‘...")
            time.sleep(60)

        entry = {
            "num": idx + 1,
            "job_task": {
                "keywords": extract_keywords(str(row.get("ì£¼ìš”ì—…ë¬´", ""))),
                "weight": row.get("ì£¼ìš”ì—…ë¬´ì¤‘ìš”ë„", 1)
            },
            "job_skills": {
                "keywords": extract_keywords(str(row.get("ìê²©ìš”ê±´ë°ìš°ëŒ€ì‚¬í•­", ""))),
                "weight": row.get("ìê²©ìš”ê±´ë°ìš°ëŒ€ì‚¬í•­ì¤‘ìš”ë„", 1)
            },
            "job_benefits": {
                "keywords": extract_keywords(str(row.get("í˜œíƒë°ë³µì§€", ""))),
                "weight": row.get("í˜œíƒë°ë³µì§€ì¤‘ìš”ë„", 1)
            }
        }
        user_input_keyword.append(entry)

        api_call_count += 1  # âœ… í˜¸ì¶œ íšŸìˆ˜ ì¦ê°€

    with open('./user_input_keyword.json', 'w', encoding='utf-8') as f:
        json.dump(user_input_keyword, f, ensure_ascii=False, indent=2)
    # =============================
    # ëˆ„ì ê³µê³  DataFrameìœ¼ë¡œ ë³€í™˜ (BGE/Jina)
    # =============================
    # ì˜ˆ) ëˆ„ì ê³µê³  DataFrame
    df_raw_bge = pd.read_excel("./bge_ëˆ„ì ê³µê³ .xlsx")
    df_raw_jina = pd.read_excel("./jina_ëˆ„ì ê³µê³ .xlsx")

    # âœ… 'ìê²©ìš”ê±´'ê³¼ 'ìš°ëŒ€ì‚¬í•­' ì—´ì„ í•©ì¹œ 'ìê²©ìš”ê±´ë°ìš°ëŒ€ì‚¬í•­' ìƒì„±
    df_raw_bge['ìê²©ìš”ê±´ë°ìš°ëŒ€ì‚¬í•­'] = df_raw_bge['ìê²©ìš”ê±´'].fillna("") + " " + df_raw_bge['ìš°ëŒ€ì‚¬í•­'].fillna("")
    df_raw_jina['ìê²©ìš”ê±´ë°ìš°ëŒ€ì‚¬í•­'] = df_raw_jina['ìê²©ìš”ê±´'].fillna("") + " " + df_raw_jina['ìš°ëŒ€ì‚¬í•­'].fillna("")

    # ê¸°ì¡´ DataFrame í•„í„°ë§ ë¶€ë¶„ ìˆ˜ì •
    top_df_BGE = df_raw_bge[['ì‹œí–‰', 'rank', 'ê³µê³ ì œëª©', 'ì£¼ìš”ì—…ë¬´', 'ìê²©ìš”ê±´ë°ìš°ëŒ€ì‚¬í•­', 'í˜œíƒë°ë³µì§€']].fillna("")
    top_df_Jina = df_raw_jina[['ì‹œí–‰', 'rank', 'ê³µê³ ì œëª©', 'ì£¼ìš”ì—…ë¬´', 'ìê²©ìš”ê±´ë°ìš°ëŒ€ì‚¬í•­', 'í˜œíƒë°ë³µì§€']].fillna("")
    
    # =============================
    # Coverage Ratio ê³„ì‚°
    # =============================
    file_keyword = "./user_input_keyword.json"
    with open(file_keyword, "r", encoding="utf-8") as f:
        user_input_keyword = json.load(f)

    start_total_time = time.time()
    api_call_count = 0

    # ê° ì…ë ¥ í‚¤ì›Œë“œì— ëŒ€í•´ ë°˜ë³µ
    for idx, user_input_json in enumerate(user_input_keyword, start=1):
        ì‹œí–‰ë²ˆí˜¸ = user_input_json.get("num", idx)
        print(f"\n===== [{ì‹œí–‰ë²ˆí˜¸}ë²ˆì§¸ ì‹œí–‰] GEMINI EVALUATION + DEBUG =====")
        result_text = evaluate_and_debug_with_gemini(user_input_json, top_df_BGE, top_df_Jina, api_call_count)
        print(result_text)
        
        api_call_count += 1

    end_total_time = time.time()
    total_duration = round(end_total_time - start_total_time, 2)
    print(f"ğŸ¯ ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ! ì´ ì‹¤í–‰ ì‹œê°„: {total_duration}ì´ˆ")

    # =============================
    # ìµœì¢… ì ìˆ˜ ê³„ì‚°
    # =============================
    coverage_df = pd.read_csv("./coverage_results.csv")
    with open('user_input_keyword.json', 'r', encoding='utf-8') as f:
        user_data = json.load(f)
    finscore_df = calculate_finscore(coverage_df, user_data)
    model_scores = finscore_df.groupby('model')['ì¢…í•©ì ìˆ˜'].sum()
    finscore_df.to_csv("final_data.csv", encoding="utf-8")

    print("\nğŸ“Š ëª¨ë¸ë³„ ì¢…í•©ì ìˆ˜ í•©ê³„:")
    print(model_scores.to_string())
    print("\nğŸ† ê²°ê³¼ ë¹„êµ:")
    if 'bge' in model_scores and 'jina' in model_scores:
        if model_scores['bge'] > model_scores['jina']:
            print(f"âœ” bge ëª¨ë¸ì´ ë” ìš°ìˆ˜í•©ë‹ˆë‹¤. (bge: {model_scores['bge']:.4f} > jina: {model_scores['jina']:.4f})")
        elif model_scores['bge'] < model_scores['jina']:
            print(f"âœ” jina ëª¨ë¸ì´ ë” ìš°ìˆ˜í•©ë‹ˆë‹¤. (jina: {model_scores['jina']:.4f} > bge: {model_scores['bge']:.4f})")
        else:
            print(f"âœ” ë‘ ëª¨ë¸ì˜ ì ìˆ˜ê°€ ë™ì¼í•©ë‹ˆë‹¤. (bge = jina = {model_scores['bge']:.4f})")
    else:
        print("â— bge ë˜ëŠ” jina ëª¨ë¸ì´ ë°ì´í„°ì— ì—†ìŠµë‹ˆë‹¤.")